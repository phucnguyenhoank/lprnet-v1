{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce269e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train dataset:\n",
      "Images: (32, 24, 94, 3), Labels: (32, 10)\n",
      "Sample 1: [17  2  2  8  7  0  0  0  0  0], length: 5\n",
      "Sample 2: [14 27  1  5  1 32 26  0  0  0], length: 7\n",
      "Sample 3: [23 17  1  7  5  4  9  0  0  0], length: 7\n",
      "Sample 4: [23 32 22  5  3  3  0  0  0  0], length: 6\n",
      "Sample 5: [14 29  1  6  2 13 14  0  0  0], length: 7\n",
      "\n",
      "Validation dataset:\n",
      "Images: (32, 24, 94, 3), Labels: (32, 10)\n",
      "Sample 1: [ 2 27 11 16  1  6  1  0  0  0], length: 7\n",
      "Sample 2: [ 4  6  4 11 29 21  4  6  0  0], length: 8\n",
      "Sample 3: [ 5  2 20 11  4  5  0  0  0  0], length: 6\n",
      "Sample 4: [ 6  2  3  7 18 32 22  0  0  0], length: 7\n",
      "Sample 5: [ 7  5  1  3 32 18  3  6  0  0], length: 8\n",
      "\n",
      "Test dataset:\n",
      "Images: (32, 24, 94, 3), Labels: (32, 10)\n",
      "Sample 1: [ 2  1  4  4 19 28  0  0  0  0], length: 6\n",
      "Sample 2: [ 3  4  5  9 34 28  3  6  0  0], length: 8\n",
      "Sample 3: [ 4  5 15 24 10  2 10 10  0  0], length: 8\n",
      "Sample 4: [ 4  9  2 11 30 21  9  4  0  0], length: 8\n",
      "Sample 5: [ 6  6 29 17  6  4  0  0  0  0], length: 6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "CHARSET = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "NUM_CLASSES = len(CHARSET) + 1  # 36 chars + blank=0\n",
    "IMG_WIDTH = 94\n",
    "IMG_HEIGHT = 24\n",
    "BATCH_SIZE = 32\n",
    "MAX_LABEL_LEN = 10\n",
    "\n",
    "# Global lookup table (shift by +1, so blank=0)\n",
    "keys = tf.constant(list(CHARSET))\n",
    "values = tf.constant(list(range(1, len(CHARSET)+1)), dtype=tf.int32)  # 1..36\n",
    "char_to_num_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(keys, values),\n",
    "    default_value=0\n",
    ")\n",
    "\n",
    "# Reverse table for decoding\n",
    "num_to_char_table = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(values, keys),\n",
    "    default_value=''\n",
    ")\n",
    "\n",
    "# Extract label from filename\n",
    "def process_filename(file_path):\n",
    "    filename = tf.strings.split(file_path, os.sep)[-1]\n",
    "    filename = tf.strings.regex_replace(filename, r'\\.[^.]+$', '')\n",
    "    filename = tf.strings.regex_replace(filename, r'_.*$', '')\n",
    "    return filename\n",
    "\n",
    "# Encode label with padding using 0 as blank\n",
    "def encode_label(label):\n",
    "    chars = tf.strings.unicode_split(label, 'UTF-8')\n",
    "    indices = tf.cast(char_to_num_table.lookup(chars), tf.int32)\n",
    "    pad_len = tf.maximum(0, MAX_LABEL_LEN - tf.shape(indices)[0])\n",
    "    indices = tf.pad(indices, [[0, pad_len]], constant_values=0)[:MAX_LABEL_LEN]\n",
    "    return indices\n",
    "\n",
    "# Load and preprocess image\n",
    "def load_and_preprocess_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    \n",
    "    label = process_filename(file_path)\n",
    "    encoded_label = encode_label(label)\n",
    "    return image, encoded_label\n",
    "\n",
    "# Create dataset\n",
    "def create_dataset(folder_path, shuffle=True):\n",
    "    files = tf.data.Dataset.list_files(str(folder_path / '*.*'), shuffle=shuffle)\n",
    "    dataset = files.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "train_dir = pathlib.Path(\"lprds/train\")\n",
    "val_dir = pathlib.Path(\"lprds/val\")\n",
    "test_dir = pathlib.Path(\"lprds/test\")\n",
    "\n",
    "train_ds = create_dataset(train_dir, shuffle=True)\n",
    "val_ds = create_dataset(val_dir, shuffle=False)\n",
    "test_ds = create_dataset(test_dir, shuffle=False)\n",
    "\n",
    "# Inspect dataset\n",
    "def inspect_dataset(dataset, name, num_samples=5):\n",
    "    print(f\"\\n{name} dataset:\")\n",
    "    for images, labels in dataset.take(1):\n",
    "        print(f\"Images: {images.shape}, Labels: {labels.shape}\")\n",
    "        for i in range(min(num_samples, BATCH_SIZE)):\n",
    "            print(f\"Sample {i+1}: {labels[i].numpy()}, length: {np.sum(labels[i].numpy() != 0)}\")\n",
    "\n",
    "inspect_dataset(train_ds, \"Train\")\n",
    "inspect_dataset(val_ds, \"Validation\")\n",
    "inspect_dataset(test_ds, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55ff58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LPRNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"LPRNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,408</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sbb1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,392</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,584</span> │ sbb2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sbb3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,173</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_flatten          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10508</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_fc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,345,152</span> │ gc_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_repeat           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">284</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gc_fc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_reshape          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gc_repeat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_concat           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)              │            │ gc_reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_conv1x1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,142</span> │ gc_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m92\u001b[0m,    │      \u001b[38;5;34m1,792\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m92\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m92\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m90\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb1 (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m90\u001b[0m,    │     \u001b[38;5;34m13,408\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m88\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ sbb1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb2 (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m88\u001b[0m,     │     \u001b[38;5;34m51,392\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sbb3 (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m88\u001b[0m,     │     \u001b[38;5;34m59,584\u001b[0m │ sbb2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m86\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ sbb3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m86\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m83\u001b[0m,     │    \u001b[38;5;34m262,400\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m83\u001b[0m,     │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m83\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m83\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m37\u001b[0m) │    \u001b[38;5;34m123,173\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_flatten          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10508\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_fc (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m1,345,152\u001b[0m │ gc_flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_repeat           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m284\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ gc_fc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_reshape          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m71\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ gc_repeat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_concat           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m71\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m165\u001b[0m)              │            │ gc_reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gc_conv1x1 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m37\u001b[0m) │      \u001b[38;5;34m6,142\u001b[0m │ gc_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,864,323</span> (7.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,864,323\u001b[0m (7.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,861,443</span> (7.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,861,443\u001b[0m (7.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1, 4, 71, 37)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def small_basic_block(Cout, name=None):\n",
    "    mid = Cout // 4\n",
    "    seq = models.Sequential(name=name)\n",
    "    seq.add(layers.Conv2D(mid, kernel_size=1, strides=1, padding=\"same\"))\n",
    "    seq.add(layers.BatchNormalization())\n",
    "    seq.add(layers.ReLU())\n",
    "    \n",
    "    seq.add(layers.Conv2D(mid, kernel_size=(3,1), strides=1, padding=\"same\")) # height=3\n",
    "    seq.add(layers.BatchNormalization())\n",
    "    seq.add(layers.ReLU())\n",
    "\n",
    "    seq.add(layers.Conv2D(mid, kernel_size=(1,3), strides=1, padding=\"same\")) # width=3\n",
    "    seq.add(layers.BatchNormalization())\n",
    "    seq.add(layers.ReLU())\n",
    "\n",
    "    seq.add(layers.Conv2D(Cout, kernel_size=1, strides=1, padding=\"same\"))\n",
    "    seq.add(layers.BatchNormalization())\n",
    "    seq.add(layers.ReLU())\n",
    "\n",
    "    return seq\n",
    "\n",
    "def global_context_block(x, num_classes, gc_dim=128, name=None):\n",
    "    \"\"\"Global context embedding as in LPRNet paper.\"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "\n",
    "    # Step 1: Global context vector from backbone\n",
    "    context = layers.Flatten(name=f\"{name}_flatten\")(x)             # (B, H*W*C)\n",
    "    context = layers.Dense(gc_dim, activation='relu', name=f\"{name}_fc\")(context)  # (B, gc_dim)\n",
    "\n",
    "    # Step 2: Tile back to spatial map\n",
    "    context = layers.RepeatVector(H * W, name=f\"{name}_repeat\")(context)  # (B, H*W, gc_dim)\n",
    "    context = layers.Reshape((H, W, gc_dim), name=f\"{name}_reshape\")(context)  # (B, H, W, gc_dim)\n",
    "\n",
    "    # Step 3: Concatenate with backbone features\n",
    "    x = layers.Concatenate(axis=-1, name=f\"{name}_concat\")([x, context])  # (B, H, W, C+gc_dim)\n",
    "\n",
    "    # Step 4: 1×1 Conv to adjust channels → num_classes\n",
    "    x = layers.Conv2D(num_classes, (1,1), strides=1, padding=\"same\", name=f\"{name}_conv1x1\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def LPRNet(num_classes=37, dropout_rate=0.5):\n",
    "    inputs = layers.Input(shape=(24,94,3), name=\"input\") # HxWxD\n",
    "\n",
    "    # Backbone\n",
    "    x = layers.Conv2D(64, (3,3), strides=1, padding=\"valid\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3,3), strides=(1,1), padding=\"valid\")(x)\n",
    "    x = small_basic_block(128,\"sbb1\")(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D((3,3), strides=(2,1), padding=\"valid\")(x) # 64? it should 128 instead?\n",
    "\n",
    "    x = small_basic_block(256,\"sbb2\")(x)\n",
    "    x = small_basic_block(256,\"sbb3\")(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3,3), strides=(2,1), padding=\"valid\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256,(1,4), strides=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(num_classes,(1, 13), strides=1, padding=\"valid\")(x)\n",
    "    # Add global context\n",
    "    x = global_context_block(x, num_classes=num_classes, gc_dim=128, name=\"gc\")\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=x, name=\"LPRNet\")\n",
    "\n",
    "# ---- Test ----\n",
    "model = LPRNet(num_classes=37)\n",
    "model.summary()\n",
    "\n",
    "dummy = tf.random.normal((1,24,94,3))\n",
    "out = model(dummy)\n",
    "print(\"Output shape:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming the LPRNet model is already defined as in your code.\n",
    "# Note: There's a typo in your model code - \"SmallBasicBlock\" should be \"small_basic_block\" (case-sensitive).\n",
    "# Correct it to small_basic_block(256, \"sbb2\")(x) and small_basic_block(256, \"sbb3\")(x)\n",
    "\n",
    "# Custom CTC loss function to handle variable label lengths\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    # y_pred shape: (B, 4, 71, 37)\n",
    "    # Reduce mean over height to get (B, 71, 37) for CTC (time steps along width)\n",
    "    y_pred = tf.reduce_mean(y_pred, axis=1)\n",
    "    \n",
    "    # Cast y_true to int32 if not already\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    \n",
    "    # Compute label lengths: number of non-zero elements (since 0 is pad)\n",
    "    label_length = tf.math.count_nonzero(y_true, axis=1, dtype=tf.int32)\n",
    "    \n",
    "    # Logit lengths: full time steps for each sample\n",
    "    batch_size = tf.shape(y_pred)[0]\n",
    "    logit_length = tf.fill([batch_size], tf.shape(y_pred)[1])\n",
    "    \n",
    "    # Compute CTC loss using tf.nn.ctc_loss\n",
    "    loss = tf.nn.ctc_loss(\n",
    "        labels=y_true,\n",
    "        logits=y_pred,\n",
    "        label_length=label_length,\n",
    "        logit_length=logit_length,\n",
    "        logits_time_major=False,\n",
    "        blank_index=0  # Assuming blank is class 0, characters are 1-36\n",
    "    )\n",
    "    \n",
    "    # Return mean loss\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0463ee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint.\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - loss: 1.1617\n",
      "Epoch 1: val_loss improved from None to 21.04774, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 867ms/step - loss: 1.3247 - val_loss: 21.0477 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729ms/step - loss: 1.2151\n",
      "Epoch 2: val_loss improved from 21.04774 to 17.16462, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 769ms/step - loss: 1.2470 - val_loss: 17.1646 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - loss: 1.0474\n",
      "Epoch 3: val_loss improved from 17.16462 to 14.24525, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 760ms/step - loss: 1.0714 - val_loss: 14.2452 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - loss: 0.8902\n",
      "Epoch 4: val_loss improved from 14.24525 to 14.04349, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 770ms/step - loss: 0.9007 - val_loss: 14.0435 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - loss: 0.7962\n",
      "Epoch 5: val_loss improved from 14.04349 to 13.17006, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 762ms/step - loss: 0.8085 - val_loss: 13.1701 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728ms/step - loss: 0.5852\n",
      "Epoch 6: val_loss did not improve from 13.17006\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 756ms/step - loss: 0.5869 - val_loss: 14.8834 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - loss: 0.7422\n",
      "Epoch 7: val_loss improved from 13.17006 to 10.75580, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 762ms/step - loss: 0.7859 - val_loss: 10.7558 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - loss: 0.8399\n",
      "Epoch 8: val_loss did not improve from 10.75580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 776ms/step - loss: 0.9901 - val_loss: 15.1945 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 1.4741\n",
      "Epoch 9: val_loss did not improve from 10.75580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 1.8649 - val_loss: 18.7250 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - loss: 2.3140\n",
      "Epoch 10: val_loss did not improve from 10.75580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 741ms/step - loss: 2.2701 - val_loss: 20.7094 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - loss: 1.6321\n",
      "Epoch 11: val_loss did not improve from 10.75580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 739ms/step - loss: 1.7031 - val_loss: 14.2422 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - loss: 1.2046\n",
      "Epoch 12: val_loss did not improve from 10.75580\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 778ms/step - loss: 1.1875 - val_loss: 17.7914 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 0.4979\n",
      "Epoch 13: val_loss did not improve from 10.75580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 775ms/step - loss: 0.4529 - val_loss: 11.0371 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750ms/step - loss: 0.2482\n",
      "Epoch 14: val_loss improved from 10.75580 to 8.93027, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 796ms/step - loss: 0.2378 - val_loss: 8.9303 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - loss: 0.1299\n",
      "Epoch 15: val_loss improved from 8.93027 to 8.87193, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 798ms/step - loss: 0.1618 - val_loss: 8.8719 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - loss: 0.1770\n",
      "Epoch 16: val_loss improved from 8.87193 to 8.01271, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 843ms/step - loss: 0.1365 - val_loss: 8.0127 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783ms/step - loss: 0.1091\n",
      "Epoch 17: val_loss did not improve from 8.01271\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 817ms/step - loss: 0.1105 - val_loss: 8.3262 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793ms/step - loss: 0.1047\n",
      "Epoch 18: val_loss improved from 8.01271 to 7.71086, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 844ms/step - loss: 0.1019 - val_loss: 7.7109 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - loss: 0.0583\n",
      "Epoch 19: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 777ms/step - loss: 0.0646 - val_loss: 7.8515 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720ms/step - loss: 0.0967\n",
      "Epoch 20: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 748ms/step - loss: 0.0915 - val_loss: 7.8797 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - loss: 0.0834\n",
      "Epoch 21: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 740ms/step - loss: 0.0811 - val_loss: 7.9145 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - loss: 0.0630\n",
      "Epoch 22: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 746ms/step - loss: 0.0670 - val_loss: 7.8666 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - loss: 0.0644\n",
      "Epoch 23: val_loss did not improve from 7.71086\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 787ms/step - loss: 0.0805 - val_loss: 8.0665 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - loss: 0.0958\n",
      "Epoch 24: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 785ms/step - loss: 0.1113 - val_loss: 8.2364 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - loss: 0.0474\n",
      "Epoch 25: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 842ms/step - loss: 0.0548 - val_loss: 8.1449 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - loss: 0.0449\n",
      "Epoch 26: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 785ms/step - loss: 0.0433 - val_loss: 8.0399 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step - loss: 0.0455\n",
      "Epoch 27: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 816ms/step - loss: 0.0367 - val_loss: 7.8554 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725ms/step - loss: 0.0456\n",
      "Epoch 28: val_loss did not improve from 7.71086\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 755ms/step - loss: 0.0523 - val_loss: 7.9484 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - loss: 0.0626\n",
      "Epoch 29: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 746ms/step - loss: 0.0624 - val_loss: 7.9104 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - loss: 0.0357\n",
      "Epoch 30: val_loss did not improve from 7.71086\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 731ms/step - loss: 0.0442 - val_loss: 7.8042 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - loss: 0.0295\n",
      "Epoch 31: val_loss improved from 7.71086 to 7.67447, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 753ms/step - loss: 0.0363 - val_loss: 7.6745 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - loss: 0.0438\n",
      "Epoch 32: val_loss improved from 7.67447 to 7.61863, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 753ms/step - loss: 0.0362 - val_loss: 7.6186 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - loss: 0.0337\n",
      "Epoch 33: val_loss improved from 7.61863 to 7.58407, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 752ms/step - loss: 0.0325 - val_loss: 7.5841 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - loss: 0.0355\n",
      "Epoch 34: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 771ms/step - loss: 0.0383 - val_loss: 7.6383 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 0.0291\n",
      "Epoch 35: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 782ms/step - loss: 0.0340 - val_loss: 7.6538 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769ms/step - loss: 0.0332\n",
      "Epoch 36: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 801ms/step - loss: 0.0313 - val_loss: 7.6702 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - loss: 0.0486\n",
      "Epoch 37: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 786ms/step - loss: 0.0440 - val_loss: 7.7111 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - loss: 0.0300\n",
      "Epoch 38: val_loss did not improve from 7.58407\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 776ms/step - loss: 0.0323 - val_loss: 7.6901 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - loss: 0.0361\n",
      "Epoch 39: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 730ms/step - loss: 0.0397 - val_loss: 7.6742 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - loss: 0.0272\n",
      "Epoch 40: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 727ms/step - loss: 0.0282 - val_loss: 7.6131 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - loss: 0.0342\n",
      "Epoch 41: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 790ms/step - loss: 0.0340 - val_loss: 7.6409 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - loss: 0.0194\n",
      "Epoch 42: val_loss did not improve from 7.58407\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 763ms/step - loss: 0.0311 - val_loss: 7.6048 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - loss: 0.0283\n",
      "Epoch 43: val_loss improved from 7.58407 to 7.58369, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 822ms/step - loss: 0.0258 - val_loss: 7.5837 - learning_rate: 6.2500e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - loss: 0.0279\n",
      "Epoch 44: val_loss improved from 7.58369 to 7.57744, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 797ms/step - loss: 0.0252 - val_loss: 7.5774 - learning_rate: 6.2500e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - loss: 0.0256\n",
      "Epoch 45: val_loss improved from 7.57744 to 7.57680, saving model to lprnet_checkpoint.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 810ms/step - loss: 0.0258 - val_loss: 7.5768 - learning_rate: 6.2500e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - loss: 0.0279\n",
      "Epoch 46: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 811ms/step - loss: 0.0339 - val_loss: 7.6535 - learning_rate: 6.2500e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step - loss: 0.0244\n",
      "Epoch 47: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 821ms/step - loss: 0.0267 - val_loss: 7.6593 - learning_rate: 6.2500e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - loss: 0.0293\n",
      "Epoch 48: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 829ms/step - loss: 0.0274 - val_loss: 7.7230 - learning_rate: 6.2500e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - loss: 0.0398\n",
      "Epoch 49: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 795ms/step - loss: 0.0387 - val_loss: 7.7209 - learning_rate: 6.2500e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - loss: 0.0257\n",
      "Epoch 50: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 732ms/step - loss: 0.0291 - val_loss: 7.6750 - learning_rate: 6.2500e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - loss: 0.0248\n",
      "Epoch 51: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 742ms/step - loss: 0.0291 - val_loss: 7.6749 - learning_rate: 3.1250e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - loss: 0.0211\n",
      "Epoch 52: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 735ms/step - loss: 0.0232 - val_loss: 7.6905 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0244\n",
      "Epoch 53: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0268 - val_loss: 7.6930 - learning_rate: 3.1250e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 0.0239\n",
      "Epoch 54: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 734ms/step - loss: 0.0265 - val_loss: 7.6376 - learning_rate: 3.1250e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - loss: 0.0322\n",
      "Epoch 55: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 740ms/step - loss: 0.0327 - val_loss: 7.6127 - learning_rate: 3.1250e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - loss: 0.0210\n",
      "Epoch 56: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 737ms/step - loss: 0.0220 - val_loss: 7.6621 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - loss: 0.0287\n",
      "Epoch 57: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 743ms/step - loss: 0.0630 - val_loss: 7.6643 - learning_rate: 1.5625e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - loss: 0.0315\n",
      "Epoch 58: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 717ms/step - loss: 0.0367 - val_loss: 7.6119 - learning_rate: 1.5625e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - loss: 0.0201\n",
      "Epoch 59: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 769ms/step - loss: 0.0293 - val_loss: 7.6077 - learning_rate: 1.5625e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - loss: 0.0383\n",
      "Epoch 60: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 734ms/step - loss: 0.0355 - val_loss: 7.6382 - learning_rate: 1.5625e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - loss: 0.0245\n",
      "Epoch 61: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 736ms/step - loss: 0.0229 - val_loss: 7.6471 - learning_rate: 7.8125e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - loss: 0.0262\n",
      "Epoch 62: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 745ms/step - loss: 0.0281 - val_loss: 7.6489 - learning_rate: 7.8125e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - loss: 0.0243\n",
      "Epoch 63: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 761ms/step - loss: 0.0266 - val_loss: 7.6502 - learning_rate: 7.8125e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0309\n",
      "Epoch 64: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0336 - val_loss: 7.6386 - learning_rate: 7.8125e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - loss: 0.0280\n",
      "Epoch 65: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 729ms/step - loss: 0.0373 - val_loss: 7.6495 - learning_rate: 7.8125e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720ms/step - loss: 0.0314\n",
      "Epoch 66: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 747ms/step - loss: 0.0292 - val_loss: 7.6463 - learning_rate: 3.9063e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - loss: 0.0220\n",
      "Epoch 67: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 774ms/step - loss: 0.0239 - val_loss: 7.6399 - learning_rate: 3.9063e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0252\n",
      "Epoch 68: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0255 - val_loss: 7.6386 - learning_rate: 3.9063e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - loss: 0.0307\n",
      "Epoch 69: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 749ms/step - loss: 0.0266 - val_loss: 7.6381 - learning_rate: 3.9063e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 0.0248\n",
      "Epoch 70: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 735ms/step - loss: 0.0246 - val_loss: 7.6356 - learning_rate: 3.9063e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0295\n",
      "Epoch 71: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 732ms/step - loss: 0.0243 - val_loss: 7.6337 - learning_rate: 1.9531e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714ms/step - loss: 0.0194\n",
      "Epoch 72: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 742ms/step - loss: 0.0214 - val_loss: 7.6331 - learning_rate: 1.9531e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - loss: 0.0167\n",
      "Epoch 73: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 727ms/step - loss: 0.0171 - val_loss: 7.6358 - learning_rate: 1.9531e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 0.0219\n",
      "Epoch 74: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 734ms/step - loss: 0.0208 - val_loss: 7.6366 - learning_rate: 1.9531e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0249\n",
      "Epoch 75: val_loss did not improve from 7.57680\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0268 - val_loss: 7.6340 - learning_rate: 1.9531e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - loss: 0.0159\n",
      "Epoch 76: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 740ms/step - loss: 0.0379 - val_loss: 7.6392 - learning_rate: 1.0000e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - loss: 0.0213\n",
      "Epoch 77: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 741ms/step - loss: 0.0201 - val_loss: 7.6401 - learning_rate: 1.0000e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - loss: 0.0196\n",
      "Epoch 78: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 758ms/step - loss: 0.0255 - val_loss: 7.6483 - learning_rate: 1.0000e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730ms/step - loss: 0.0277\n",
      "Epoch 79: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 759ms/step - loss: 0.0300 - val_loss: 7.6435 - learning_rate: 1.0000e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - loss: 0.0193\n",
      "Epoch 80: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 752ms/step - loss: 0.0211 - val_loss: 7.6405 - learning_rate: 1.0000e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - loss: 0.0203\n",
      "Epoch 81: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 743ms/step - loss: 0.0253 - val_loss: 7.6445 - learning_rate: 1.0000e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711ms/step - loss: 0.0335\n",
      "Epoch 82: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 739ms/step - loss: 0.0274 - val_loss: 7.6486 - learning_rate: 1.0000e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - loss: 0.0227\n",
      "Epoch 83: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 745ms/step - loss: 0.0232 - val_loss: 7.6480 - learning_rate: 1.0000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - loss: 0.0242\n",
      "Epoch 84: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 747ms/step - loss: 0.0250 - val_loss: 7.6413 - learning_rate: 1.0000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - loss: 0.0227\n",
      "Epoch 85: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 737ms/step - loss: 0.0266 - val_loss: 7.6394 - learning_rate: 1.0000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703ms/step - loss: 0.0265\n",
      "Epoch 86: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0312 - val_loss: 7.6383 - learning_rate: 1.0000e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - loss: 0.0314\n",
      "Epoch 87: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 738ms/step - loss: 0.0280 - val_loss: 7.6383 - learning_rate: 1.0000e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - loss: 0.0201\n",
      "Epoch 88: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 738ms/step - loss: 0.0234 - val_loss: 7.6395 - learning_rate: 1.0000e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - loss: 0.0166\n",
      "Epoch 89: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 736ms/step - loss: 0.0318 - val_loss: 7.6570 - learning_rate: 1.0000e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - loss: 0.0257\n",
      "Epoch 90: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 728ms/step - loss: 0.0250 - val_loss: 7.6576 - learning_rate: 1.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 0.0220\n",
      "Epoch 91: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 735ms/step - loss: 0.0222 - val_loss: 7.6597 - learning_rate: 1.0000e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - loss: 0.0391\n",
      "Epoch 92: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 726ms/step - loss: 0.0270 - val_loss: 7.6637 - learning_rate: 1.0000e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - loss: 0.0183\n",
      "Epoch 93: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 737ms/step - loss: 0.0240 - val_loss: 7.6624 - learning_rate: 1.0000e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - loss: 0.0318\n",
      "Epoch 94: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 734ms/step - loss: 0.0243 - val_loss: 7.6655 - learning_rate: 1.0000e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - loss: 0.0179\n",
      "Epoch 95: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 728ms/step - loss: 0.0221 - val_loss: 7.6628 - learning_rate: 1.0000e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - loss: 0.0261\n",
      "Epoch 96: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 733ms/step - loss: 0.0264 - val_loss: 7.6618 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - loss: 0.0262\n",
      "Epoch 97: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 730ms/step - loss: 0.0229 - val_loss: 7.6595 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - loss: 0.0190\n",
      "Epoch 98: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 730ms/step - loss: 0.0274 - val_loss: 7.6603 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - loss: 0.0289\n",
      "Epoch 99: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 732ms/step - loss: 0.0258 - val_loss: 7.6590 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - loss: 0.0202\n",
      "Epoch 100: val_loss did not improve from 7.57680\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 743ms/step - loss: 0.0209 - val_loss: 7.6558 - learning_rate: 1.0000e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 5.9951\n",
      "Test Loss: 5.995123863220215\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers, callbacks\n",
    "\n",
    "# Load the saved model if resuming, otherwise instantiate a new one\n",
    "try:\n",
    "    model = tf.keras.models.load_model(\n",
    "        \"lprnet_checkpoint.keras\",\n",
    "        custom_objects={\"ctc_loss\": ctc_loss},\n",
    "        compile=False\n",
    "    )\n",
    "    print(\"Loaded model from checkpoint.\")\n",
    "except:\n",
    "    print(\"No checkpoint found, creating new model.\")\n",
    "    model = LPRNet(num_classes=37, dropout_rate=0.5)  # Assuming LPRNet is defined\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=ctc_loss\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"lprnet_checkpoint.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr_callback = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  # Reduce learning rate by half\n",
    "    patience=5,  # Wait 5 epochs before reducing\n",
    "    min_lr=1e-6,  # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_ds,  # Assuming train_ds is defined\n",
    "    validation_data=val_ds,  # Assuming val_ds is defined\n",
    "    epochs=100,\n",
    "    initial_epoch=0,  # Set to the epoch you want to start from if resuming\n",
    "    callbacks=[checkpoint_callback, reduce_lr_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_loss = model.evaluate(test_ds)  # Assuming test_ds is defined\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"lprnet_model_final.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e302a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted License Plate: 8427XX29\n"
     ]
    }
   ],
   "source": [
    "# Character mapping (adjust based on your dataset)\n",
    "# Example: 0=blank, 1-10=digits 0-9, 11-36=A-Z\n",
    "char_map = {0: '', 1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9',\n",
    "            11: 'A', 12: 'B', 13: 'C', 14: 'D', 15: 'E', 16: 'F', 17: 'G', 18: 'H', 19: 'I', 20: 'J',\n",
    "            21: 'K', 22: 'L', 23: 'M', 24: 'N', 25: 'O', 26: 'P', 27: 'Q', 28: 'R', 29: 'S', 30: 'T',\n",
    "            31: 'U', 32: 'V', 33: 'W', 34: 'X', 35: 'Y', 36: 'Z'}\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    # Load image (assuming it's a file path; adjust if image is a numpy array)\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # Normalize to [0, 1]\n",
    "    img = tf.image.resize(img, [24, 94])  # Resize to match model input\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension: (1, 24, 94, 3)\n",
    "    return img\n",
    "\n",
    "# Function to decode CTC output\n",
    "def decode_ctc_output(logits, char_map):\n",
    "    # Reduce mean over height to get (B, 71, 37)\n",
    "    logits = tf.reduce_mean(logits, axis=1)  # Shape: (1, 71, 37)\n",
    "    \n",
    "    # CTC greedy decoder\n",
    "    decoded, _ = tf.nn.ctc_greedy_decoder(\n",
    "        inputs=tf.transpose(logits, perm=[1, 0, 2]),  # Time-major: (71, 1, 37)\n",
    "        sequence_length=tf.ones([1], dtype=tf.int32) * logits.shape[1],\n",
    "        blank_index=0\n",
    "    )\n",
    "    \n",
    "    # Convert sparse tensor to dense and extract the sequence\n",
    "    decoded_sequence = tf.sparse.to_dense(decoded[0]).numpy()[0]\n",
    "    \n",
    "    # Map indices to characters\n",
    "    prediction = ''.join([char_map.get(int(idx), '') for idx in decoded_sequence])\n",
    "    return prediction\n",
    "\n",
    "# Function to predict license plate from an image\n",
    "def predict_license_plate(image_path, model_path=\"lprnet_checkpoint.keras\"):\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(\n",
    "        model_path,\n",
    "        custom_objects={\"ctc_loss\": ctc_loss},\n",
    "        compile=False\n",
    "    )\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img = preprocess_image(image_path)\n",
    "    \n",
    "    # Get model prediction\n",
    "    logits = model(img)  # Shape: (1, 4, 71, 37)\n",
    "    \n",
    "    # Decode the prediction\n",
    "    prediction = decode_ctc_output(logits, char_map)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example image path\n",
    "    image_path = r\"lprds\\test\\8427XX29.jpg\"  # Replace with actual image path\n",
    "    try:\n",
    "        predicted_plate = predict_license_plate(image_path, model_path=\"lprnet_checkpoint.keras\")\n",
    "        print(f\"Predicted License Plate: {predicted_plate}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting license plate: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cf953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b744597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lprnet-v1 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
